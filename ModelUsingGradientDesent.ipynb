{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV3OECoKr70MpWNI9zTdjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadcui/Machine_Learning/blob/main/ModelUsingGradientDesent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/murpi/wilddata/master/quests/cars.csv\", usecols=['mpg','weightlbs'])\n",
        "x = np.array(df[['weightlbs']])\n",
        "y = np.array(df['mpg'])\n",
        "\n",
        "def compute_cost(x, y, w, b):\n",
        "    m = x.shape[0]\n",
        "    cost = 0\n",
        "    for i in range(m):\n",
        "        f_wb = w * x[i].item() + b\n",
        "        cost = cost + (f_wb - y[i])**2\n",
        "    total_cost = 1 / (2 * m) * cost\n",
        "    return float(total_cost)\n",
        "\n",
        "def compute_gradient(x, y, w, b):\n",
        "    m = x.shape[0]\n",
        "    dj_dw = 0\n",
        "    dj_db = 0\n",
        "    for i in range(m):\n",
        "        xi = x[i].item()\n",
        "        yi = y[i].item()\n",
        "        f_wb = w * xi + b\n",
        "        dj_dw += (f_wb - yi) * xi\n",
        "        dj_db += (f_wb - yi)\n",
        "    dj_dw /= m\n",
        "    dj_db /= m\n",
        "    return dj_dw, dj_db\n",
        "\n",
        "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n",
        "    J_history = []\n",
        "    p_history = []\n",
        "    w = w_in\n",
        "    b = b_in\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        dj_dw, dj_db = gradient_function(x, y, w, b)\n",
        "        w = w - alpha * dj_dw\n",
        "        b = b - alpha * dj_db\n",
        "\n",
        "        if i < 100000:\n",
        "            J_history.append(cost_function(x, y, w, b))\n",
        "            p_history.append([w, b])\n",
        "\n",
        "        if i % (num_iters // 10) == 0:\n",
        "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
        "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
        "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
        "\n",
        "    return w, b, J_history, p_history\n",
        "\n",
        "\n",
        "# Initialize parameters\n",
        "initial_w = 0\n",
        "initial_b = 0\n",
        "alpha = 0.0000001  # Much smaller learning rate\n",
        "iterations = 1000\n",
        "\n",
        "# Run gradient descent\n",
        "w, b, _, _ = gradient_descent(x, y, initial_w, initial_b, alpha, iterations, compute_cost, compute_gradient)\n",
        "\n",
        "# Predict the MPG for 3000 lbs\n",
        "weight = 2000\n",
        "predicted_mpg = w * weight + b\n",
        "print(f\"Predicted MPG for {weight} lbs: {predicted_mpg:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99WP4alpCZTg",
        "outputId": "c877de60-c839-46f4-8909-3f65e7a8b6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost 8.76e+01  dj_dw: -6.420e+04, dj_db: -2.314e+01   w:  6.420e-03, b: 2.31448e-06\n",
            "Iteration  100: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 3.61585e-05\n",
            "Iteration  200: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 6.99570e-05\n",
            "Iteration  300: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 1.03755e-04\n",
            "Iteration  400: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 1.37554e-04\n",
            "Iteration  500: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 1.71352e-04\n",
            "Iteration  600: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 2.05150e-04\n",
            "Iteration  700: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 2.38949e-04\n",
            "Iteration  800: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 2.72747e-04\n",
            "Iteration  900: Cost 8.75e+01  dj_dw:  1.041e-03, dj_db: -3.380e+00   w:  6.568e-03, b: 3.06545e-04\n",
            "Predicted MPG for 2000 lbs: 13.14\n"
          ]
        }
      ]
    }
  ]
}